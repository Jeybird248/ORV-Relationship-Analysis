{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install spacy\n",
    "!pip install networkx\n",
    "!pip install matplotlib.pyplot\n",
    "!pip install re\n",
    "!pip install os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "\n",
    "!python -m spacy download en_core_web_sm\n",
    "# installing and importing libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definitions\n",
    "\n",
    "def load_books(book_folder):\n",
    "    texts = []\n",
    "    for file_name in os.listdir(book_folder):\n",
    "        file_path = os.path.join(book_folder, file_name)\n",
    "    \n",
    "        # Check if the path is a file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            texts.append(file_path)\n",
    "    return texts\n",
    "\n",
    "def filter_entity(ent_list, character_df):\n",
    "    return [ent for ent in ent_list\n",
    "            if ent in list(character_df.character)\n",
    "            or ent in list(character_df.character_firstname)\n",
    "            or any(ent in alias_list for alias_list in character_df.aliases)]\n",
    "\n",
    "def extract_last_name(full_name, last_names):\n",
    "    for last_name in last_names:\n",
    "        if last_name in full_name[0]:\n",
    "            return last_name\n",
    "    return full_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in text and langauge model\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "texts = load_books(\"book_split_output\")\n",
    "# for text in texts:\n",
    "#     book_doc = NER(open(text, 'r', encoding='utf-8').read())\n",
    "book_doc = NER(open(texts[0], 'r', encoding='utf-8').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommy\\AppData\\Local\\Temp\\ipykernel_11992\\2167441617.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sent_entity_df_filtered['character_entities'] = sent_entity_df_filtered.apply(lambda row: [extract_last_name(row['character_entities'], character_df['character_lastname'])], axis=1)\n"
     ]
    }
   ],
   "source": [
    "# load in names of characters\n",
    "character_df = pd.read_csv(\"names.csv\")\n",
    "\n",
    "\n",
    "# add columns for different variations of name\n",
    "character_df[\"character\"] = character_df[\"character\"].apply(lambda x: re.sub(r\"[^\\w\\s]+\", \"\", x))\n",
    "character_df[\"character_firstname\"] = character_df[\"character\"].apply(lambda x: x.split(\" \", 1) [0])\n",
    "character_df[\"character_lastname\"] = character_df[\"character\"].apply(lambda x: x.split(\" \", 1) [-1])\n",
    "character_df[\"aliases\"] = character_df[\"aliases\"].apply(lambda x: [] if isinstance(x, float) else x.split(\",\"))\n",
    "\n",
    "# use NER to process and grab the list of entities and their sentences\n",
    "sent_entity_df = []\n",
    "\n",
    "for sent in book_doc.sents:\n",
    "    entity_list = [ent.text for ent in sent.ents]\n",
    "    sent_entity_df.append({\"sentence\": sent, \"entities\": entity_list})\n",
    "\n",
    "# turn list into df\n",
    "sent_entity_df = pd.DataFrame(sent_entity_df)\n",
    "\n",
    "# filter out only the character names\n",
    "sent_entity_df[\"character_entities\"] = sent_entity_df[\"entities\"].apply(lambda x: filter_entity(x, character_df))\n",
    "\n",
    "# filter out sentences that don't have any entities in them\n",
    "sent_entity_df_filtered = sent_entity_df[sent_entity_df[\"character_entities\"].map(len) > 0]\n",
    "\n",
    "# set entity name to last name of entity to aggregate same names i.e. Kim Dokja vs Dokja should be counted as same\n",
    "sent_entity_df_filtered['character_entities'] = sent_entity_df_filtered.apply(lambda row: [extract_last_name(row['character_entities'], character_df['character_lastname'])], axis=1)\n",
    "pd.reset_option('^display.', silent = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scroll through 5 lines at a time to aggregate relationships between characters and reorder to make sure A -> B is the same as B -> A\n",
    "window_size = 5\n",
    "relationships = []\n",
    "\n",
    "for i in range(sent_entity_df_filtered.index[-1]):\n",
    "    end_i = min(i+5, sent_entity_df_filtered.index[-1])\n",
    "    char_list = sum((sent_entity_df_filtered.loc[i : end_i].character_entities), [])\n",
    "\n",
    "    char_unique = [char_list[i] for i in range(len(char_list))\n",
    "                   if (i == 0) or char_list[i] != char_list[i-1]]\n",
    "    if len(char_unique) > 1:\n",
    "        for idx, a in enumerate(char_unique[:-1]):\n",
    "            b = char_unique[idx + 1]\n",
    "            relationships.append({\"source\": a, \"target\": b})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the occurences of relationships between characters\n",
    "relationship_df = pd.DataFrame(relationships)\n",
    "relationship_df.head(10)\n",
    "relationship_df = pd.DataFrame(np.sort(relationship_df.values, axis = 1), columns = relationship_df.columns)\n",
    "\n",
    "relationship_df[\"value\"] = 1\n",
    "relationship_df = relationship_df.groupby([\"source\", \"target\"], sort=False, as_index = False). sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dokja</td>\n",
       "      <td>Sangah</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kang</td>\n",
       "      <td>Sangah</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hyunsung</td>\n",
       "      <td>Sangah</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hyunsung</td>\n",
       "      <td>Namwoon</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Han</td>\n",
       "      <td>Namwoon</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Namwoon</td>\n",
       "      <td>Sangah</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Namwoon</td>\n",
       "      <td>One</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dokja</td>\n",
       "      <td>Hyunsung</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gilyoung</td>\n",
       "      <td>Sangah</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Black Flame Dragon</td>\n",
       "      <td>Demon</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source    target  value\n",
       "0               Dokja    Sangah      4\n",
       "1                Kang    Sangah      5\n",
       "2            Hyunsung    Sangah     99\n",
       "3            Hyunsung   Namwoon     17\n",
       "4                 Han   Namwoon     24\n",
       "5             Namwoon    Sangah      3\n",
       "6             Namwoon       One      5\n",
       "7               Dokja  Hyunsung      6\n",
       "8            Gilyoung    Sangah     80\n",
       "9  Black Flame Dragon     Demon      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
